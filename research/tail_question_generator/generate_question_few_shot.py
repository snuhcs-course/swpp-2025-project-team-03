import argparse
import json
import os

from dotenv import load_dotenv
from langchain_core.output_parsers.json import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# Load API key
load_dotenv()
if "OPENAI_API_KEY" not in os.environ:
    raise ValueError("OPENAI_API_KEY is not set")


LLM_MODEL = "gpt-5-nano"
llm = ChatOpenAI(
    model=LLM_MODEL,
    temperature=0,
    model_kwargs={"response_format": {"type": "json_object"}},
)
# --- Few-shot Examples ---
FEW_SHOT_EXAMPLES = [
    # 1. Correct + High Confidence (Deeper Question)
    {
        "input": {
            "question": "í˜ì´ ì¼ì •í•  ë•Œ, ì§ˆëŸ‰ì´ ì»¤ì§€ë©´ ê°€ì†ë„ëŠ” ì–´ë–»ê²Œ ë³€í• ê¹Œìš”?",
            "model_answer": "F=ma ê³µì‹ì— ë”°ë¼, í˜ì´ ì¼ì •í•˜ë©´ ì§ˆëŸ‰ì´ ì»¤ì§ˆìˆ˜ë¡ ê°€ì†ë„ëŠ” ì‘ì•„ì§‘ë‹ˆë‹¤.",
            "hint": "F=ma ê³µì‹ì„ ìƒê°í•´ë³´ì„¸ìš”.",
            "student_answer": "ê°€ì†ë„ëŠ” ì‘ì•„ì ¸ìš”.",
            "eval_grade": 4.5,
        },
        "output": {
            "topic": "ë‰´í„´ì˜ ì œ2ë²•ì¹™ ì‹¬í™”",
            "question": "ë§Œì•½ ë‘ ë¬¼ì²´ Aì™€ Bê°€ ìˆê³ , Bì˜ ì§ˆëŸ‰ì´ Aì˜ ë‘ ë°°ë¼ë©´, ê°™ì€ í˜ì„ ê°€í–ˆì„ ë•Œ ë‘ ë¬¼ì²´ì˜ ê°€ì†ë„ ë¹„ìœ¨ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?",
            "model_answer": "Bì˜ ê°€ì†ë„ëŠ” Aì˜ ê°€ì†ë„ì˜ 1/2ì´ ë©ë‹ˆë‹¤. ê°€ì†ë„ëŠ” ì§ˆëŸ‰ì— ë°˜ë¹„ë¡€í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            "hint": "ê°€ì†ë„ì™€ ì§ˆëŸ‰ì˜ ê´€ê³„ë¥¼ ë¹„ìœ¨ë¡œ ìƒê°í•´ë³´ì„¸ìš”.",
            "explanation": "ì´ ì§ˆë¬¸ì€ ë‰´í„´ì˜ ì œ2ë²•ì¹™ì„ ë‹¨ìˆœíˆ ì´í•´í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ì§ˆëŸ‰ê³¼ ê°€ì†ë„ì˜ ë°˜ë¹„ë¡€ ê´€ê³„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.",
            "difficulty": "hard",
        },
    },
    # 2. Correct + Low Confidence (Reinforcing Question)
    {
        "input": {
            "question": "ë‹¬ì—ì„œ ë¬¼ì²´ì˜ ë¬´ê²Œê°€ ì§€êµ¬ë³´ë‹¤ ì‘ê²Œ ëŠê»´ì§€ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?",
            "model_answer": "ë‹¬ì˜ ì§ˆëŸ‰ì´ ì§€êµ¬ë³´ë‹¤ ì‘ì•„ì„œ, ì¤‘ë ¥ë„ ì§€êµ¬ë³´ë‹¤ ì•½í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            "hint": "ì¤‘ë ¥ì€ ì²œì²´ì˜ ì§ˆëŸ‰ì— ì˜í–¥ì„ ë°›ìŠµë‹ˆë‹¤.",
            "student_answer": "ìŒ ë‹¬ì˜ ì¤‘ë ¥ì´ ì•½í•´ì„œì¸ ê²ƒ ê°™ì•„ìš”.",
            "eval_grade": 1.5,
        },
        "output": {
            "topic": "ì¤‘ë ¥ê³¼ ì§ˆëŸ‰ì˜ ê´€ê³„",
            "question": "ê·¸ë ‡ë‹¤ë©´, ì§ˆëŸ‰ì´ ë§¤ìš° í° ëª©ì„±ì—ì„œëŠ” ê°™ì€ ë¬¼ì²´ì˜ ë¬´ê²Œê°€ ì§€êµ¬ì—ì„œë³´ë‹¤ í´ê¹Œìš”, ì‘ì„ê¹Œìš”?",
            "model_answer": "ëª©ì„±ì—ì„œëŠ” ë¬´ê²Œê°€ ë” í½ë‹ˆë‹¤. ëª©ì„±ì˜ ì§ˆëŸ‰ì´ ì§€êµ¬ë³´ë‹¤ í›¨ì”¬ í¬ê¸° ë•Œë¬¸ì— ì¤‘ë ¥ë„ ë” ê°•í•©ë‹ˆë‹¤.",
            "hint": "ì²œì²´ì˜ ì§ˆëŸ‰ì´ í´ìˆ˜ë¡ ì¤‘ë ¥ë„ ê°•í•´ì§‘ë‹ˆë‹¤.",
            "explanation": "ì´ ì§ˆë¬¸ì€ í•™ìƒì´ ì¤‘ë ¥ê³¼ ì²œì²´ì˜ ì§ˆëŸ‰ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ëª…í™•íˆ ì´í•´í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ìì‹ ê°ì„ ì‹¬ì–´ì£¼ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.",
            "difficulty": "medium",
        },
    },
    # 3. Incorrect + High Confidence (Misconception-correcting Question)
    {
        "input": {
            "question": "ì‹ë¬¼ì´ ê´‘í•©ì„±ì„ í•˜ëŠ” ì£¼ëœ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "model_answer": "ìŠ¤ìŠ¤ë¡œ ì‚´ì•„ê°€ëŠ” ë° í•„ìš”í•œ ì–‘ë¶„(í¬ë„ë‹¹)ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.",
            "hint": "ì‹ë¬¼ë„ ì—ë„ˆì§€ê°€ í•„ìš”í•´ìš”.",
            "student_answer": "ì‚°ì†Œë¥¼ ë§Œë“¤ì–´ì„œ ìš°ë¦¬ì—ê²Œ ì£¼ê¸° ìœ„í•´ì„œìš”!",
            "eval_grade": 4.0,
        },
        "output": {
            "topic": "ê´‘í•©ì„±ì˜ ëª©ì ",
            "question": "ê´‘í•©ì„±ì˜ ê²°ê³¼ë¡œ ì‚°ì†Œê°€ ë‚˜ì˜¤ëŠ” ê²ƒì€ ë§ì§€ë§Œ, ê·¸ê²ƒì´ ì‹ë¬¼ì˜ ì£¼ëœ ëª©ì ì¼ê¹Œìš”? ì‹ë¬¼ ìì‹ ì—ê²Œ ê°€ì¥ ë¨¼ì € í•„ìš”í•œ ê²ƒì€ ë¬´ì—‡ì¼ì§€ ìƒê°í•´ë³´ì„¸ìš”.",
            "model_answer": "ì‹ë¬¼ ìì‹ ì—ê²Œ ê°€ì¥ ë¨¼ì € í•„ìš”í•œ ê²ƒì€ ì‚´ì•„ê°€ëŠ” ë° ì‚¬ìš©í•  ì—ë„ˆì§€ì›, ì¦‰ ì–‘ë¶„(í¬ë„ë‹¹)ì…ë‹ˆë‹¤. ì‚°ì†ŒëŠ” ê·¸ ê³¼ì •ì—ì„œ ë‚˜ì˜¤ëŠ” ë¶€ì‚°ë¬¼ì…ë‹ˆë‹¤.",
            "hint": "ëª¨ë“  ìƒë¬¼ì€ ìƒì¡´ì„ ìœ„í•´ ì—ë„ˆì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            "explanation": "í•™ìƒì´ 'ê´‘í•©ì„±=ì‚°ì†Œ ìƒì„±'ì´ë¼ëŠ” ë‹¨ìˆœí•œ ê²°ê³¼ì—ë§Œ ì§‘ì¤‘í•˜ëŠ” ì˜¤ê°œë…ì„ ê°€ì§€ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì§ˆë¬¸ì€ ê´‘í•©ì„±ì˜ ì£¼ëœ ëª©ì ì´ ì‹ë¬¼ ìì‹ ì˜ ìƒì¡´ì„ ìœ„í•œ ì–‘ë¶„ ìƒì‚°ì„ì„ ëª…í™•íˆ í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.",
            "difficulty": "medium",
        },
    },
    # 4. Incorrect + Low Confidence (Scaffolding Question)
    {
        "input": {
            "question": "ì†Œê¸ˆë¬¼ì—ì„œ ì†Œê¸ˆê³¼ ë¬¼ì„ ì–´ë–»ê²Œ ë¶„ë¦¬í•  ìˆ˜ ìˆì„ê¹Œìš”?",
            "model_answer": "ë¬¼ì„ ë“ì—¬ ì¦ë°œì‹œí‚¤ë©´ ì†Œê¸ˆë§Œ ë‚¨ìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ ì¦ë¥˜ë¼ê³  í•©ë‹ˆë‹¤.",
            "hint": "ë¬¼ê³¼ ì†Œê¸ˆì˜ ë“ëŠ”ì ì´ ë‹¤ë¥¸ ê²ƒì„ ì´ìš©í•´ìš”.",
            "student_answer": "ì˜ ëª¨ë¥´ê² ì–´ìš”... í•„í„°ë¡œ ê±°ë¥´ë©´ ì•ˆë˜ë‚˜ìš”?",
            "eval_grade": 0.5,
        },
        "output": {
            "topic": "í˜¼í•©ë¬¼ì˜ ë¶„ë¦¬",
            "question": "ì†Œê¸ˆë¬¼ì€ ì†Œê¸ˆ ì…ìê°€ ë¬¼ì— ì™„ì „íˆ ë…¹ì•„ìˆëŠ” ìƒíƒœì˜ˆìš”. ì´ëŸ° ì•¡ì²´ë¥¼ ë“ì´ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”? ë¬¼ë§Œ ìˆ˜ì¦ê¸°ë¡œ ë‚ ì•„ê°€ì§€ ì•Šì„ê¹Œìš”?",
            "model_answer": "ë¬¼ì„ ë“ì´ë©´ ìˆ˜ì¦ê¸°ê°€ ë˜ì–´ ë‚ ì•„ê°€ê³ , ë“ëŠ”ì ì´ í›¨ì”¬ ë†’ì€ ì†Œê¸ˆì€ ê·¸ëŒ€ë¡œ ë‚¨ê²Œ ë©ë‹ˆë‹¤.",
            "hint": "ë¼ë©´ì„ ë“ì¼ ë•Œ ë¬¼ì´ ì¡¸ì•„ë“¤ë©´ ë” ì§œì§€ëŠ” ê²ƒì„ ìƒê°í•´ë³´ì„¸ìš”.",
            "explanation": "í•™ìƒì´ ìš©í•´ì™€ í˜¼í•©ë¬¼ì˜ ë¶„ë¦¬ ê°œë…ì„ ì–´ë ¤ì›Œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ í˜„ìƒì¸ 'ì¦ë°œ'ì— ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„í•˜ì—¬ ê¸°ë³¸ì ì¸ ë¶„ë¦¬ ì›ë¦¬ë¥¼ ì´í•´í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.",
            "difficulty": "easy",
        },
    },
]


few_shot_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are an adaptive tutoring agent that generates a **single follow-up (tail) quiz question**
to improve learning outcomes based on the student's previous answer and confidence level.

# Core Goal
Use the student's performance data (correctness + confidence) to design the next question
that best supports conceptual understanding, correction of misconceptions, or deeper reasoning.
     
# Task Overview
You will:
1. Analyze whether the student's answer is correct or incorrect.
2. Interpret the student's confidence level (`eval_grade` between 0.0 and 5.0).
3. Decide which of the four follow-up strategies fits best.
4. Generate a single new question in korean that supports conceptual improvement.(You can utilize the original question, model answer, and hint if needed.)

# Case Guidelines (Correctness Ã— Confidence)
Follow these strategies strictly:

1. âœ… Correct + ğŸ”¼ High Confidence (â‰¥ 2.5)
   â†’ Create a **deeper, more applied, or cross-concept question**.
     - Extend the concept to a new situation.
     - Encourage transfer of knowledge or synthesis across topics.
     - Difficulty: **hard** or **medium**

2. âœ… Correct + ğŸ”½ Low Confidence (< 2.5)
   â†’ Create a **concept-reinforcing question**.
     - Revisit the same concept with a different perspective or representation.
     - Help the student confirm understanding and build confidence.
     - Difficulty: **medium**

3. âŒ Incorrect + ğŸ”¼ High Confidence (â‰¥ 2.5)
   â†’ Create a **misconception-correcting question**.
     - Identify the likely misconception in the student's answer.
     - Ask a contrasting or diagnostic question that exposes and corrects the misunderstanding.
     - Include an explanation that clarifies the correct concept.
     - Difficulty: **medium** or **easy**

4. âŒ Incorrect + ğŸ”½ Low Confidence (< 2.5)
   â†’ Create a **scaffolding or foundational question**.
     - Simplify the context and focus on the essential concept.
     - Use concrete examples or guided reasoning to help recovery.
     - Difficulty: **easy**

# Output Requirements
- Ensure the question is conceptually aligned with the original topic.
- Include a clear model answer and concise explanation.
- Explicitly label difficulty as "easy", "medium", or "hard".
- The question should help the student **progress** from their current understanding state.
- The question should be shorter than 30 words in korean, and the explanation should be shorter than 50 words in korean.

# Output Format
Return the result strictly as a JSON structure:

{{
  "response": {{
    "topic": "<short topic name>",
    "question": "<the follow-up question>",
    "model_answer": "<ideal answer>",
    "hint": "<hint for the question>",
    "explanation": "<why this question matters and what concept it tests>",
    "difficulty": "easy | medium | hard"
  }}
}}

# Rules
- No Markdown, lists, or commentary outside the JSON.
- Output must be factual, pedagogically sound, and self-contained.
- Respond in Korean.

---
## Examples
{examples}
---
""",
        ),
        (
            "user",
            """Original Question: {question}
Model Answer: {model_answer}
Student Answer: {student_answer}
Confidence Score: {eval_grade}
""",
        ),
    ]
)


def build_tail_quiz_single_call(question, model_answer, student_answer, eval_grade):
    few_shot_str = json.dumps(FEW_SHOT_EXAMPLES, ensure_ascii=False, indent=2)

    msg = few_shot_prompt.format_messages(
        question=question,
        model_answer=model_answer,
        student_answer=student_answer,
        eval_grade=str(eval_grade),
        examples=few_shot_str,
    )
    response = llm.invoke(msg).content
    parser = JsonOutputParser()
    try:
        data = parser.parse(response)
        tail_quiz = data["response"]
    except Exception as e:
        print("âš ï¸ JSON parsing failed, showing raw output:\n", response)
        raise e
    return tail_quiz  # dict


def main():
    parser = argparse.ArgumentParser(
        description="Generate a single follow-up (tail) quiz question based on student's previous answer and confidence level."
    )
    parser.add_argument("--question", "-q", type=str, default="ì™œ ë¬¼ì²´ëŠ” ì§€êµ¬ì—ì„œ ë•…ìœ¼ë¡œ ë–¨ì–´ì§€ëŠ”ê°€?", help="ì›ë¬¸ ì§ˆë¬¸")
    parser.add_argument(
        "--model-answer",
        "-m",
        type=str,
        default="ì§€êµ¬ì˜ ì¤‘ë ¥ì´ ë¬¼ì²´ë¥¼ ì¤‘ì‹¬ ë°©í–¥ìœ¼ë¡œ ëŒì–´ë‹¹ê¸°ê¸° ë•Œë¬¸ì´ë‹¤.",
        help="ëª¨ë²”ë‹µì•ˆ",
    )
    parser.add_argument("--student-answer", "-s", type=str, default="ë¬´ê±°ì›Œì„œ ë” ë¹¨ë¦¬ ë–¨ì–´ì§„ë‹¤.", help="í•™ìƒë‹µì•ˆ")
    parser.add_argument("--confidence", "-c", type=float, default=1.9, help="ìì‹ ê° ì ìˆ˜(0.0~5.0)")
    parser.add_argument("--json", action="store_true", help="ê²°ê³¼ë¥¼ JSON ì›ë³¸ìœ¼ë¡œ ì¶œë ¥")

    args = parser.parse_args()

    result = build_tail_quiz_single_call(
        question=args.question,
        model_answer=args.model_answer,
        student_answer=args.student_answer,
        eval_grade=args.confidence,
    )  # dict: {"topic": ..., "question": ..., "model_answer": ..., "explanation": ..., "difficulty": ...}

    # ì¶œë ¥
    print("\nâœ… Generated 1 tail quiz:\n")
    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(f"Topic:       {result.get('topic', '')}")
        print(f"Q:           {result.get('question', '')}")
        print(f"A:           {result.get('model_answer', '')}")
        print(f"Explanation: {result.get('explanation', '')}")
        print(f"Difficulty:  {result.get('difficulty', '')}")


if __name__ == "__main__":
    main()
